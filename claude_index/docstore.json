{"docstore/ref_doc_info": {"697366ad-6178-4dc0-9563-c62376bf54e0": {"node_ids": ["8fdcd5d8-0e93-4859-a98e-e358e9a16060"], "metadata": {"file_path": "test_simple_search.py", "file_type": ".py", "file_name": "test_simple_search.py", "file_size": 2176}}, "bbb98c35-7b97-4ae5-9ca1-58dbc4b1a8d2": {"node_ids": ["071400f5-a926-45f2-98e3-561158dc325b"], "metadata": {"file_path": "requirements.txt", "file_type": ".txt", "file_name": "requirements.txt", "file_size": 382}}, "21fd938d-2298-4743-8c2d-a1754f4a83d1": {"node_ids": ["bbbd87d7-508f-4041-87cb-9590d2c3f786"], "metadata": {"file_path": "test_search.py", "file_type": ".py", "file_name": "test_search.py", "file_size": 765}}, "37934402-8bf4-4850-944e-21fc4ecadd57": {"node_ids": ["263432b9-dd92-4eb5-9147-1a13ad8eb92a"], "metadata": {"file_path": "pyproject.toml", "file_type": ".toml", "file_name": "pyproject.toml", "file_size": 2394}}, "f0b9f952-4eef-486d-851d-9ede5e8b2043": {"node_ids": ["f45ed685-0050-4e5d-b7bf-20dc3b8307ee", "5263c7d9-8d40-449f-a423-46df09298c43", "42cb9e8c-cf4b-4667-bc8e-0ffa83fd78fe"], "metadata": {"file_path": "README.md", "file_type": ".md", "file_name": "README.md", "file_size": 7741}}, "0302bcac-3671-411b-9718-2e6aa790625f": {"node_ids": ["d517282d-44c9-4ca4-8cb5-a1fbfd1374da"], "metadata": {"file_path": "test_indexer.py", "file_type": ".py", "file_name": "test_indexer.py", "file_size": 3195}}, "dd1f44ac-60e2-45d9-8825-4e0bb1f099e6": {"node_ids": ["e66cbdd2-ca39-41aa-8723-65d9e26f3e1e"], "metadata": {"file_path": ".claude/settings.local.json", "file_type": ".json", "file_name": "settings.local.json", "file_size": 135}}, "f3e3c43a-ca2f-41ce-9595-2a318444f954": {"node_ids": ["8bdc9650-5544-421d-9787-b330984b5eae"], "metadata": {"file_path": "src/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 431}}, "aedb53a0-4f44-4a05-a159-05dba419a589": {"node_ids": ["4a5a38ea-1804-469e-8ef4-40cc4d13c433", "958785fc-32e6-413b-934b-0d8194ed1c57", "7ae2711c-832b-4e6d-be84-f96148f09e12"], "metadata": {"file_path": "src/integration/claude.py", "file_type": ".py", "file_name": "claude.py", "file_size": 11248}}, "c549e2f8-8b7d-44e1-a33e-2b209fdd944d": {"node_ids": ["ebeec2dd-c886-463e-b9c2-ec4469cf38c9"], "metadata": {"file_path": "src/integration/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 132}}, "5f088bf9-80d3-4f10-8033-ad3b83aae3a2": {"node_ids": ["e31ebede-0333-44d5-bde3-e05a19b4ae07"], "metadata": {"file_path": "src/cli/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 44}}, "cdb60186-b0f3-46cf-b596-630fecbf4ddf": {"node_ids": ["54ba9dd5-ad05-48a4-9caa-4eb1e682f3e8"], "metadata": {"file_path": "src/cli/search.py", "file_type": ".py", "file_name": "search.py", "file_size": 2688}}, "ee727f5e-5f98-457e-9589-554599b9491c": {"node_ids": ["9f06c207-fbad-4213-a38f-86adf748a048", "f56e646a-58f5-4bbb-9b2c-2caebd679eab"], "metadata": {"file_path": "src/cli/main.py", "file_type": ".py", "file_name": "main.py", "file_size": 7547}}, "d85215e1-f865-48a0-b868-2455a609c183": {"node_ids": ["1eac9a52-74c1-422c-9cc8-1d27a6491b15"], "metadata": {"file_path": "src/search/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 125}}, "b9ddedf7-3bdd-444d-b747-b8bd92ea7a04": {"node_ids": ["37e62612-f96d-4886-9a1c-33522855e3ba", "c8fb6bb7-2170-45d9-a650-83464749cc45", "8ec39862-e8a1-4237-96e1-405f5bc365a5"], "metadata": {"file_path": "src/search/engine.py", "file_type": ".py", "file_name": "engine.py", "file_size": 10357}}, "3a5c2614-53a2-415f-9de0-385f40a911c7": {"node_ids": ["7321996d-6ade-4de9-a50b-69c1adf43d77"], "metadata": {"file_path": "src/indexer/dummy_embedder.py", "file_type": ".py", "file_name": "dummy_embedder.py", "file_size": 933}}, "03658bb1-a01d-44ae-9ac4-72e4dd081cf8": {"node_ids": ["39876ac9-f351-433c-a3c8-4b3426850700"], "metadata": {"file_path": "src/indexer/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 116}}, "0a1ac987-95cf-430b-90e8-3c0a787adac9": {"node_ids": ["dd09a0f4-8d36-4e4d-982c-fa7a7f322cf6", "8ca1b90d-c8fa-46fd-8756-b357d02a9b2a"], "metadata": {"file_path": "src/indexer/core.py", "file_type": ".py", "file_name": "core.py", "file_size": 7362}}}, "docstore/data": {"8fdcd5d8-0e93-4859-a98e-e358e9a16060": {"__data__": {"id_": "8fdcd5d8-0e93-4859-a98e-e358e9a16060", "embedding": null, "metadata": {"file_path": "test_simple_search.py", "file_type": ".py", "file_name": "test_simple_search.py", "file_size": 2176}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "697366ad-6178-4dc0-9563-c62376bf54e0", "node_type": "4", "metadata": {"file_path": "test_simple_search.py", "file_type": ".py", "file_name": "test_simple_search.py", "file_size": 2176}, "hash": "064507407450c3a6aba05e18d8b4ef25fdf6b984e18e4e1e6838c0d23da15c7a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "#!/usr/bin/env python3\n\"\"\"\nTest search with simple in-memory storage\n\"\"\"\n\nfrom src.indexer.dummy_embedder import DummyEmbedding\nfrom llama_index.core import VectorStoreIndex, Document\nfrom llama_index.core.node_parser import SimpleNodeParser\nimport os\n\ndef test_simple_search():\n    print(\"\ud83e\uddea Testing simple search functionality...\")\n    \n    # Get all Python files in src/\n    docs = []\n    for root, dirs, files in os.walk(\"src\"):\n        for file in files:\n            if file.endswith('.py'):\n                file_path = os.path.join(root, file)\n                try:\n                    with open(file_path, 'r', encoding='utf-8') as f:\n                        content = f.read()\n                    \n                    docs.append(Document(\n                        text=content,\n                        metadata={'file_path': file_path, 'file_type': '.py'}\n                    ))\n                except Exception as e:\n                    print(f\"Warning: Could not read {file_path}: {e}\")\n    \n    print(f\"\ud83d\udcc4 Loaded {len(docs)} Python files\")\n    \n    # Simple splitting\n    splitter = SimpleNodeParser.from_defaults(chunk_size=500, chunk_overlap=50)\n    nodes = splitter.get_nodes_from_documents(docs)\n    print(f\"\ud83d\udd0d Created {len(nodes)} chunks\")\n    \n    # Create index with dummy embedder (in-memory)\n    embed_model = DummyEmbedding()\n    index = VectorStoreIndex(nodes, embed_model=embed_model)\n    print(\"\u2705 Index created\")\n    \n    # Test searches\n    test_queries = [\n        \"indexer semantic search\",\n        \"Claude Code integration\", \n        \"vector store FAISS\",\n        \"command line interface\",\n        \"dummy embedder\"\n    ]\n    \n    for query in test_queries:\n        print(f\"\\n\ud83d\udd0d Searching for: '{query}'\")\n        \n        retriever = index.as_retriever(similarity_top_k=3)\n        results = retriever.retrieve(query)\n        \n        for i, result in enumerate(results, 1):\n            file_path = result.metadata.get('file_path', 'unknown')\n            score = getattr(result, 'score', 'N/A')\n            print(f\"  {i}. {file_path} (score: {score})\")\n            print(f\"     {result.text[:80]}...\")\n\nif __name__ == \"__main__\":\n    test_simple_search()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2176, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "071400f5-a926-45f2-98e3-561158dc325b": {"__data__": {"id_": "071400f5-a926-45f2-98e3-561158dc325b", "embedding": null, "metadata": {"file_path": "requirements.txt", "file_type": ".txt", "file_name": "requirements.txt", "file_size": 382}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bbb98c35-7b97-4ae5-9ca1-58dbc4b1a8d2", "node_type": "4", "metadata": {"file_path": "requirements.txt", "file_type": ".txt", "file_name": "requirements.txt", "file_size": 382}, "hash": "0cb5c3ae15e2b6e71a58366e986058ade0506f7b34fbe98f3fe60fd7a078294e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Core dependencies for Claude Codebase Indexer\nllama-index==0.10.40\nfaiss-cpu==1.7.4\ntiktoken==0.5.1\nopenai==1.3.7\n\n# Optional: GPU acceleration (comment out faiss-cpu above if using this)\n# faiss-gpu==1.7.4\n\n# Additional utilities\npathlib\nlogging\nargparse\nsubprocess\ntempfile\njson\ntyping\n\n# Development dependencies (optional)\npytest>=7.0.0\nblack>=22.0.0\nflake8>=5.0.0\nmypy>=1.0.0", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 382, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bbbd87d7-508f-4041-87cb-9590d2c3f786": {"__data__": {"id_": "bbbd87d7-508f-4041-87cb-9590d2c3f786", "embedding": null, "metadata": {"file_path": "test_search.py", "file_type": ".py", "file_name": "test_search.py", "file_size": 765}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "21fd938d-2298-4743-8c2d-a1754f4a83d1", "node_type": "4", "metadata": {"file_path": "test_search.py", "file_type": ".py", "file_name": "test_search.py", "file_size": 765}, "hash": "92c8c01b6001a9e825deee2420a2d39d59e9745bfd5cff34eddfbb537f2f5078", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "#!/usr/bin/env python3\n\"\"\"\nTest search functionality directly\n\"\"\"\n\nfrom src.search.engine import SemanticSearchEngine\n\ndef test_search():\n    engine = SemanticSearchEngine(\"./claude_index\")\n    \n    print(\"\ud83d\udd0d Testing search engine...\")\n    \n    if engine.load_index():\n        print(\"\u2705 Index loaded successfully\")\n        \n        # Test search\n        results = engine.search(\"indexer semantic search\", top_k=3)\n        print(f\"Found {len(results)} results\")\n        \n        for i, result in enumerate(results, 1):\n            print(f\"{i}. {result['file_path']} (score: {result.get('score', 'N/A')})\")\n            print(f\"   {result['content'][:100]}...\")\n            \n    else:\n        print(\"\u274c Failed to load index\")\n\nif __name__ == \"__main__\":\n    test_search()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 765, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "263432b9-dd92-4eb5-9147-1a13ad8eb92a": {"__data__": {"id_": "263432b9-dd92-4eb5-9147-1a13ad8eb92a", "embedding": null, "metadata": {"file_path": "pyproject.toml", "file_type": ".toml", "file_name": "pyproject.toml", "file_size": 2394}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "37934402-8bf4-4850-944e-21fc4ecadd57", "node_type": "4", "metadata": {"file_path": "pyproject.toml", "file_type": ".toml", "file_name": "pyproject.toml", "file_size": 2394}, "hash": "420e9519f915eec9bce1867198a8462c7b2a97a4fad97ce858363de83b716f7b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[build-system]\nrequires = [\"setuptools>=45\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"claude-codebase-indexer\"\nversion = \"0.1.0\"\ndescription = \"Semantic search system for Claude Code integration\"\nreadme = \"README.md\"\nrequires-python = \">=3.8\"\nlicense = {text = \"MIT\"}\nauthors = [\n    {name = \"Claude Codebase Indexer Team\"},\n]\nkeywords = [\"claude\", \"code\", \"search\", \"semantic\", \"ai\", \"llm\"]\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.8\",\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Topic :: Software Development :: Libraries :: Python Modules\",\n    \"Topic :: Text Processing :: Indexing\",\n]\ndependencies = [\n    \"llama-index>=0.10.40\",\n    \"faiss-cpu>=1.7.4\",\n    \"tiktoken>=0.5.1\",\n    \"openai>=1.3.7\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest>=7.0.0\",\n    \"black>=22.0.0\",\n    \"flake8>=5.0.0\",\n    \"mypy>=1.0.0\",\n]\ngpu = [\n    \"faiss-gpu>=1.7.4\",\n]\n\n[project.urls]\nHomepage = \"https://github.com/your-username/claude-codebase-indexer\"\nDocumentation = \"https://github.com/your-username/claude-codebase-indexer#readme\"\nRepository = \"https://github.com/your-username/claude-codebase-indexer.git\"\nIssues = \"https://github.com/your-username/claude-codebase-indexer/issues\"\n\n[project.scripts]\nclaude-indexer = \"src.cli.main:main\"\nclaude-search = \"src.cli.search:main\"\n\n[tool.setuptools.packages.find]\nwhere = [\".\"]\ninclude = [\"src*\"]\nexclude = [\"tests*\"]\n\n[tool.black]\nline-length = 88\ntarget-version = ['py38']\ninclude = '\\.pyi?$'\nextend-exclude = '''\n/(\n  # directories\n  \\.eggs\n  | \\.git\n  | \\.hg\n  | \\.mypy_cache\n  | \\.tox\n  | \\.venv\n  | build\n  | dist\n)/\n'''\n\n[tool.mypy]\npython_version = \"3.8\"\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\ndisallow_incomplete_defs = true\ncheck_untyped_defs = true\ndisallow_untyped_decorators = true\nno_implicit_optional = true\nwarn_redundant_casts = true\nwarn_unused_ignores = true\nwarn_no_return = true\nwarn_unreachable = true\nstrict_equality = true\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = \"test_*.py\"\npython_classes = \"Test*\"\npython_functions = \"test_*\"\naddopts = \"-v --tb=short\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2394, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f45ed685-0050-4e5d-b7bf-20dc3b8307ee": {"__data__": {"id_": "f45ed685-0050-4e5d-b7bf-20dc3b8307ee", "embedding": null, "metadata": {"file_path": "README.md", "file_type": ".md", "file_name": "README.md", "file_size": 7741}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0b9f952-4eef-486d-851d-9ede5e8b2043", "node_type": "4", "metadata": {"file_path": "README.md", "file_type": ".md", "file_name": "README.md", "file_size": 7741}, "hash": "6ed6b0ed6450a131a339b86a23f63d45622ca6f6461815f1e2cc8396ab53685b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5263c7d9-8d40-449f-a423-46df09298c43", "node_type": "1", "metadata": {}, "hash": "b2e6b7789992d191d042cf7c89c70543f746d202893aed5765104c3f8992c7eb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Claude Codebase Indexer\n\nA semantic search system that enhances Claude Code with intelligent codebase understanding. Index your entire project and get relevant context automatically injected into Claude Code conversations.\n\n## Features\n\n- \ud83e\udde0 **Semantic Search** - Find code by meaning, not just keywords\n- \ud83e\udd16 **Claude Code Integration** - Automatic context injection\n- \ud83d\udcc1 **Multi-language Support** - Python, JavaScript, TypeScript, and more\n- \u26a1 **Fast Retrieval** - FAISS-powered vector search\n- \ud83c\udfaf **Smart Filtering** - Search by file type, relevance score\n- \ud83d\udcac **Interactive Mode** - Real-time search and exploration\n\n## Quick Start\n\n### Installation\n\n```bash\n# Clone the repository\ngit clone <repository-url>\ncd claude-codebase-indexer\n\n# Install dependencies\npip install -r requirements.txt\n\n# Set OpenAI API key (required for embeddings)\nexport OPENAI_API_KEY=\"your-api-key-here\"\n```\n\n### Basic Usage\n\n```bash\n# 1. Index your codebase\npython -m src.cli.main index /path/to/your/project\n\n# 2. Search your code\npython -m src.cli.main search \"authentication logic\"\n\n# 3. Run Claude Code with context\npython -m src.cli.main claude \"How does user login work?\"\n```\n\n## Installation\n\n### Prerequisites\n\n- Python 3.8+\n- OpenAI API key\n- Claude Code CLI installed\n\n### Setup\n\n1. **Install Python dependencies:**\n   ```bash\n   pip install llama-index==0.10.40 faiss-cpu tiktoken openai\n   ```\n\n2. **Set up API keys:**\n   ```bash\n   export OPENAI_API_KEY=\"sk-your-openai-key\"\n   ```\n\n3. **Verify Claude Code is installed:**\n   ```bash\n   claude-code --version\n   ```\n\n## Usage\n\n### Indexing\n\nIndex your codebase to create a searchable vector database:\n\n```bash\n# Index current directory\npython -m src.cli.main index .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1709, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5263c7d9-8d40-449f-a423-46df09298c43": {"__data__": {"id_": "5263c7d9-8d40-449f-a423-46df09298c43", "embedding": null, "metadata": {"file_path": "README.md", "file_type": ".md", "file_name": "README.md", "file_size": 7741}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0b9f952-4eef-486d-851d-9ede5e8b2043", "node_type": "4", "metadata": {"file_path": "README.md", "file_type": ".md", "file_name": "README.md", "file_size": 7741}, "hash": "6ed6b0ed6450a131a339b86a23f63d45622ca6f6461815f1e2cc8396ab53685b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f45ed685-0050-4e5d-b7bf-20dc3b8307ee", "node_type": "1", "metadata": {"file_path": "README.md", "file_type": ".md", "file_name": "README.md", "file_size": 7741}, "hash": "8c59623f119642d94d4ea366dc7f34072510000c598848a98a2d63897b9aa4cb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "42cb9e8c-cf4b-4667-bc8e-0ffa83fd78fe", "node_type": "1", "metadata": {}, "hash": "a4c09c1eb635af562eae1cb2ba697847078ed5891a0231144664917e98035f74", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "**Set up API keys:**\n   ```bash\n   export OPENAI_API_KEY=\"sk-your-openai-key\"\n   ```\n\n3. **Verify Claude Code is installed:**\n   ```bash\n   claude-code --version\n   ```\n\n## Usage\n\n### Indexing\n\nIndex your codebase to create a searchable vector database:\n\n```bash\n# Index current directory\npython -m src.cli.main index .\n\n# Index specific project\npython -m src.cli.main index /path/to/project\n\n# Custom index location\npython -m src.cli.main index /path/to/project --index-path ./my_index\n\n# Force reindex\npython -m src.cli.main index /path/to/project --force\n```\n\n### Searching\n\nSearch your indexed codebase:\n\n```bash\n# Basic search\npython -m src.cli.main search \"database connection\"\n\n# Filter by file types\npython -m src.cli.main search \"error handling\" --file-types py js\n\n# Get more results\npython -m src.cli.main search \"authentication\" --top-k 10\n\n# Interactive search mode\npython -m src.cli.main search --interactive\n```\n\n### Claude Code Integration\n\nRun Claude Code with automatic context injection:\n\n```bash\n# Basic usage\npython -m src.cli.main claude \"Add error handling to the login function\"\n\n# Specify context search\npython -m src.cli.main claude \"Refactor this code\" --context-query \"refactoring patterns\"\n\n# Filter context by file type\npython -m src.cli.main claude \"Fix the bug\" --file-types py --top-k 5\n\n# Pass additional Claude Code arguments\npython -m src.cli.main claude \"Optimize performance\" --claude-args --model claude-3-opus\n\n# Interactive mode\npython -m src.cli.main claude \"Help me understand this codebase\" --interactive\n```\n\n### Other Commands\n\n```bash\n# Show index statistics\npython -m src.cli.main stats\n\n# Find similar files\npython -m src.cli.main similar src/auth.py\n\n# Update existing index\npython -m src.cli.main update /path/to/project\n\n# Quick search (standalone)\npython -m src.cli.search \"function definition\"\n```\n\n## Configuration\n\n### Supported File Types\n\nBy default, the indexer processes these file types:\n- **Code**: `.py`, `.js`, `.ts`, `.jsx`, `.tsx`, `.java`, `.cpp`, `.c`, `.h`, `.hpp`, `.cs`, `.php`, `.rb`, `.go`, `.rs`, `.swift`, `.kt`, `.scala`\n- **Scripts**: `.sh`, `.sql`\n- **Config**: `.yaml`, `.yml`, `.json`, `.toml`, `.cfg`, `.ini`\n- **Docs**: `.md`, `.txt`, `.rst`\n\n### Excluded Directories\n\nThese directories are automatically skipped:\n- `node_modules`, `.git`, `__pycache__`, `.pytest_cache`\n- `venv`, `env`, `.venv`, `dist`, `build`, `.next`\n- `target`, `bin`, `obj`, `.mypy_cache`, `coverage`\n\n### Customization\n\nEdit `src/indexer/core.py` to:\n- Add new file extensions\n- Modify chunk sizes\n- Adjust skip patterns\n- Change embedding models\n\n## Examples\n\n### Find Authentication Code\n```bash\n$ python -m src.cli.main search \"user authentication login\"\n\n# Results show relevant auth-related code across your project\n```\n\n### Debug with Context\n```bash\n$ python -m src.cli.main claude \"Why is the login failing?\" --file-types py js\n\n# Claude gets relevant authentication code as context\n```\n\n### Explore Similar Files\n```bash\n$ python -m src.cli.main similar src/models/user.py\n\n# Shows files with similar patterns/structure\n```\n\n### Interactive Exploration\n```bash\n$ python -m src.cli.main search --interactive\n\n\ud83d\udd0d Claude Code Semantic Search\n\ud83d\udcc1 Project: /path/to/your/project\n\ud83d\udcca 127 files, 1,439 chunks indexed\n\n\ud83e\udd16 Search query > database migration\n# Shows relevant database code\n\n\ud83e\udd16 Search query > type:py class definition\n# Shows Python classes\n\n\ud83e\udd16 Search query > similar:src/auth.py\n# Shows files similar to auth.py\n```\n\n## How It Works\n\n1. **Indexing Phase:**\n   - Scans your codebase for supported file types\n   - Splits code into semantic chunks using code-aware parsing\n   - Generates embeddings using OpenAI's text-embedding-ada-002\n   - Stores vectors in FAISS index for fast retrieval\n\n2.", "mimetype": "text/plain", "start_char_idx": 1390, "end_char_idx": 5144, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "42cb9e8c-cf4b-4667-bc8e-0ffa83fd78fe": {"__data__": {"id_": "42cb9e8c-cf4b-4667-bc8e-0ffa83fd78fe", "embedding": null, "metadata": {"file_path": "README.md", "file_type": ".md", "file_name": "README.md", "file_size": 7741}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f0b9f952-4eef-486d-851d-9ede5e8b2043", "node_type": "4", "metadata": {"file_path": "README.md", "file_type": ".md", "file_name": "README.md", "file_size": 7741}, "hash": "6ed6b0ed6450a131a339b86a23f63d45622ca6f6461815f1e2cc8396ab53685b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5263c7d9-8d40-449f-a423-46df09298c43", "node_type": "1", "metadata": {"file_path": "README.md", "file_type": ".md", "file_name": "README.md", "file_size": 7741}, "hash": "f306534d371596629c31cf9bfce029e5f59677fbb60cc92d6bfe954070f068a4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "**Indexing Phase:**\n   - Scans your codebase for supported file types\n   - Splits code into semantic chunks using code-aware parsing\n   - Generates embeddings using OpenAI's text-embedding-ada-002\n   - Stores vectors in FAISS index for fast retrieval\n\n2. **Search Phase:**\n   - Converts your query to an embedding\n   - Finds most similar code chunks using vector similarity\n   - Ranks results by relevance score\n   - Formats output for Claude Code consumption\n\n3. **Integration Phase:**\n   - Automatically searches for relevant context\n   - Injects context into Claude Code session\n   - Maintains conversation flow with enhanced understanding\n\n## Troubleshooting\n\n### Common Issues\n\n**Index not found:**\n```bash\n\u274c Index not found at ./claude_index\n# Solution: Run indexer first\npython -m src.cli.main index /path/to/project\n```\n\n**No OpenAI API key:**\n```bash\n\u274c OpenAI API key not found\n# Solution: Set environment variable\nexport OPENAI_API_KEY=\"your-key-here\"\n```\n\n**Poor search results:**\n- Try different search terms\n- Increase `--top-k` value\n- Check if files were indexed (`stats` command)\n- Use file type filters\n\n**Claude Code not found:**\n```bash\n\u274c claude-code command not found\n# Solution: Install Claude Code CLI\npip install anthropic-claude-code\n```\n\n### Performance Tips\n\n- **Large codebases**: Index incrementally or use `--force` sparingly\n- **Better context**: Use specific search queries rather than generic terms\n- **Memory usage**: Reduce chunk sizes in `core.py` if needed\n- **Search speed**: Keep indexes on fast storage (SSD)\n\n## Advanced Usage\n\n### Custom Embedding Models\n\nEdit `src/indexer/core.py` to use different embedding models:\n```python\n# Use different OpenAI model\nembed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n\n# Or use local embeddings (requires additional setup)\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nembed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n```\n\n### Shell Integration\n\nAdd to your `.bashrc` or `.zshrc`:\n```bash\n# Quick aliases\nalias cindex='python -m src.cli.main index'\nalias csearch='python -m src.cli.main search'\nalias cclaude='python -m src.cli.main claude'\n\n# Project-specific function\nclaude-enhanced() {\n    python /path/to/claude-codebase-indexer/src/cli/main.py claude \"$@\"\n}\n```\n\n### CI/CD Integration\n\nUpdate indexes automatically:\n```yaml\n# .github/workflows/update-index.yml\nname: Update Code Index\non:\n  push:\n    branches: [main]\njobs:\n  update-index:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Update index\n        run: python -m src.cli.main update . --force\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Add tests if applicable\n5. Submit a pull request\n\n## License\n\nMIT License - see LICENSE file for details", "mimetype": "text/plain", "start_char_idx": 4890, "end_char_idx": 7741, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d517282d-44c9-4ca4-8cb5-a1fbfd1374da": {"__data__": {"id_": "d517282d-44c9-4ca4-8cb5-a1fbfd1374da", "embedding": null, "metadata": {"file_path": "test_indexer.py", "file_type": ".py", "file_name": "test_indexer.py", "file_size": 3195}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0302bcac-3671-411b-9718-2e6aa790625f", "node_type": "4", "metadata": {"file_path": "test_indexer.py", "file_type": ".py", "file_name": "test_indexer.py", "file_size": 3195}, "hash": "5199ebbe9f96688741821b5e9d71bfe508fabd412462cd9885d6b5d051ab3166", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "#!/usr/bin/env python3\n\"\"\"\nTest the indexer with a simple dummy embedder\n\"\"\"\n\nimport numpy as np\nfrom llama_index.core.embeddings import BaseEmbedding\nfrom llama_index.core import VectorStoreIndex, Document\nfrom llama_index.core.node_parser import CodeSplitter\nfrom llama_index.vector_stores.faiss import FaissVectorStore\nfrom llama_index.core.storage.storage_context import StorageContext\nimport faiss\n\nclass DummyEmbedding(BaseEmbedding):\n    \"\"\"Simple dummy embedder for testing\"\"\"\n    \n    def _get_text_embedding(self, text: str) -> list[float]:\n        # Create a simple hash-based embedding with fixed dimension\n        hash_val = hash(text)\n        np.random.seed(abs(hash_val) % (2**32))\n        embedding = np.random.normal(0, 1, 384)  # Fixed dimension\n        return embedding.tolist()\n    \n    def _get_query_embedding(self, query: str) -> list[float]:\n        return self._get_text_embedding(query)\n    \n    async def _aget_query_embedding(self, query: str) -> list[float]:\n        return self._get_text_embedding(query)\n    \n    async def _aget_text_embedding(self, text: str) -> list[float]:\n        return self._get_text_embedding(text)\n\ndef test_basic_indexing():\n    \"\"\"Test basic indexing functionality\"\"\"\n    print(\"\ud83e\uddea Testing basic indexing...\")\n    \n    # Create some test documents\n    docs = [\n        Document(text=\"def authenticate_user(username, password):\\n    return verify_credentials(username, password)\", \n                metadata={'file_path': 'auth.py', 'file_type': '.py'}),\n        Document(text=\"class UserModel:\\n    def __init__(self, username):\\n        self.username = username\", \n                metadata={'file_path': 'models.py', 'file_type': '.py'}),\n        Document(text=\"function handleLogin(event) {\\n    const username = event.target.username.value;\\n    authenticate(username);\\n}\",\n                metadata={'file_path': 'login.js', 'file_type': '.js'}),\n    ]\n    \n    # Use simple text splitter instead\n    from llama_index.core.node_parser import SimpleNodeParser\n    splitter = SimpleNodeParser.from_defaults(\n        chunk_size=500,\n        chunk_overlap=50\n    )\n    \n    nodes = splitter.get_nodes_from_documents(docs)\n    print(f\"Created {len(nodes)} chunks from {len(docs)} documents\")\n    \n    # Create vector store\n    embed_dim = 384\n    faiss_index = faiss.IndexFlatL2(embed_dim)\n    vector_store = FaissVectorStore(faiss_index=faiss_index)\n    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n    \n    # Create index with dummy embedder\n    embed_model = DummyEmbedding()\n    index = VectorStoreIndex(nodes, storage_context=storage_context, embed_model=embed_model)\n    \n    print(\"\u2705 Index created successfully!\")\n    \n    # Test retrieval\n    retriever = index.as_retriever(similarity_top_k=2)\n    results = retriever.retrieve(\"user authentication login\")\n    \n    print(f\"\ud83d\udd0d Search results for 'user authentication login':\")\n    for i, result in enumerate(results):\n        print(f\"  {i+1}. {result.metadata.get('file_path', 'unknown')} (score: {getattr(result, 'score', 'N/A')})\")\n        print(f\"     {result.text[:100]}...\")\n    \n    return index\n\nif __name__ == \"__main__\":\n    test_basic_indexing()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3195, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e66cbdd2-ca39-41aa-8723-65d9e26f3e1e": {"__data__": {"id_": "e66cbdd2-ca39-41aa-8723-65d9e26f3e1e", "embedding": null, "metadata": {"file_path": ".claude/settings.local.json", "file_type": ".json", "file_name": "settings.local.json", "file_size": 135}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dd1f44ac-60e2-45d9-8825-4e0bb1f099e6", "node_type": "4", "metadata": {"file_path": ".claude/settings.local.json", "file_type": ".json", "file_name": "settings.local.json", "file_size": 135}, "hash": "7e82f21d7ca50a5c235734a536022c41ef6038c2800804bb616553a8881ea924", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "{\n  \"permissions\": {\n    \"allow\": [\n      \"Bash(python test:*)\",\n      \"Bash(rm:*)\",\n      \"Bash(python:*)\"\n    ],\n    \"deny\": []\n  }\n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 135, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8bdc9650-5544-421d-9787-b330984b5eae": {"__data__": {"id_": "8bdc9650-5544-421d-9787-b330984b5eae", "embedding": null, "metadata": {"file_path": "src/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 431}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f3e3c43a-ca2f-41ce-9595-2a318444f954", "node_type": "4", "metadata": {"file_path": "src/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 431}, "hash": "4bf6ac3d7a3f67c016dc1a0647353a85f11e58b2c59745783bce87bd5557db65", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"\nClaude Codebase Indexer\n\nA semantic search system that enhances Claude Code with intelligent codebase understanding.\n\"\"\"\n\n__version__ = \"0.1.0\"\n__author__ = \"Claude Codebase Indexer Team\"\n\nfrom .indexer.core import CodebaseIndexer\nfrom .search.engine import SemanticSearchEngine\nfrom .integration.claude import ClaudeCodeIntegration\n\n__all__ = [\n    \"CodebaseIndexer\",\n    \"SemanticSearchEngine\", \n    \"ClaudeCodeIntegration\"\n]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 431, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4a5a38ea-1804-469e-8ef4-40cc4d13c433": {"__data__": {"id_": "4a5a38ea-1804-469e-8ef4-40cc4d13c433", "embedding": null, "metadata": {"file_path": "src/integration/claude.py", "file_type": ".py", "file_name": "claude.py", "file_size": 11248}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "aedb53a0-4f44-4a05-a159-05dba419a589", "node_type": "4", "metadata": {"file_path": "src/integration/claude.py", "file_type": ".py", "file_name": "claude.py", "file_size": 11248}, "hash": "608e237cb49bea74f284d6cbf78955819cd01d85f3f29112f4b8a259f736499b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "958785fc-32e6-413b-934b-0d8194ed1c57", "node_type": "1", "metadata": {}, "hash": "54ea45ef3ce49cb26daff0371d8ccc07df4f151eff3b0bd9843e4fcc17d89559", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "#!/usr/bin/env python3\n\"\"\"\nClaude Code integration with semantic context injection\n\"\"\"\n\nimport subprocess\nimport tempfile\nimport argparse\nimport sys\nimport logging\nimport select\nfrom pathlib import Path\nfrom typing import List, Optional, Dict, Any\n\nfrom src.search.engine import SemanticSearchEngine\n\nlogger = logging.getLogger(__name__)\n\nclass ClaudeCodeIntegration:\n    \"\"\"Enhanced Claude Code with semantic context\"\"\"\n    \n    def __init__(self, index_path: str = \"./claude_index\"):\n        self.search_engine = SemanticSearchEngine(index_path)\n        \n    def run_with_context(self, \n                        user_query: str, \n                        context_query: Optional[str] = None,\n                        top_k: int = 3,\n                        file_types: Optional[List[str]] = None,\n                        claude_args: Optional[List[str]] = None,\n                        interactive: bool = False) -> None:\n        \"\"\"Run Claude Code with semantic context\"\"\"\n        \n        # Load search index\n        if not self.search_engine.load_index():\n            print(\"\u274c Could not load search index. Run indexer first.\")\n            sys.exit(1)\n        \n        # Use user query for context if no specific context query provided\n        search_query = context_query or user_query\n        \n        print(f\"\ud83d\udd0d Searching for context: '{search_query}'\")\n        \n        # Get relevant context based on file types\n        if file_types:\n            results = self.search_engine.search_by_file_type(search_query, file_types, top_k)\n        else:\n            results = self.search_engine.search(search_query, top_k)\n        \n        if not results:\n            print(f\"\u26a0\ufe0f  No relevant context found for '{search_query}'\")\n            print(\"Running Claude Code without additional context...\")\n            context = \"\"\n        else:\n            context = self.search_engine.format_for_claude(results, search_query)\n            print(f\"\u2705 Found {len(results)} relevant code sections\")\n        \n        # Prepare the enhanced prompt\n        if context:\n            enhanced_prompt = f\"\"\"Here's relevant context from the codebase:\n\n{context}\n\n---\n\nUser Request: {user_query}\n\nPlease help with the above request using the provided codebase context.\"\"\"\n        else:\n            enhanced_prompt = user_query\n        \n        if interactive:\n            self._run_interactive_claude(enhanced_prompt, claude_args)\n        else:\n            self._run_claude_with_file(enhanced_prompt, claude_args)\n    \n    def _run_claude_with_file(self, prompt: str, claude_args: Optional[List[str]] = None) -> None:\n        \"\"\"Run Claude Code with prompt in temporary file\"\"\"\n        # Write to temporary file\n        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:\n            f.write(prompt)\n            temp_file = f.name\n        \n        try:\n            # Prepare Claude Code command\n            cmd = ['claude-code']\n            if claude_args:\n                cmd.extend(claude_args)\n            cmd.extend(['--file', temp_file])\n            \n            print(f\"\ud83e\udd16 Running Claude Code with context...\")\n            result = subprocess.run(cmd, capture_output=False)\n            sys.exit(result.returncode)\n            \n        finally:\n            # Clean up\n            Path(temp_file).unlink(missing_ok=True)\n    \n    def _run_interactive_claude(self, initial_prompt: str, claude_args: Optional[List[str]] = None) -> None:\n        \"\"\"Run Claude Code in interactive mode with initial context\"\"\"\n        print(\"\ud83e\udd16 Starting Claude Code in interactive mode...\")\n        print(\"\ud83d\udccb Initial context has been prepared.\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3625, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "958785fc-32e6-413b-934b-0d8194ed1c57": {"__data__": {"id_": "958785fc-32e6-413b-934b-0d8194ed1c57", "embedding": null, "metadata": {"file_path": "src/integration/claude.py", "file_type": ".py", "file_name": "claude.py", "file_size": 11248}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "aedb53a0-4f44-4a05-a159-05dba419a589", "node_type": "4", "metadata": {"file_path": "src/integration/claude.py", "file_type": ".py", "file_name": "claude.py", "file_size": 11248}, "hash": "608e237cb49bea74f284d6cbf78955819cd01d85f3f29112f4b8a259f736499b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4a5a38ea-1804-469e-8ef4-40cc4d13c433", "node_type": "1", "metadata": {"file_path": "src/integration/claude.py", "file_type": ".py", "file_name": "claude.py", "file_size": 11248}, "hash": "3c41ff5b07ba010da3c34cc7cbae37bb32d52b9bb00394d880441f2ab96d992e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7ae2711c-832b-4e6d-be84-f96148f09e12", "node_type": "1", "metadata": {}, "hash": "5a3aea8461f4d162a39ae481c8cbe9bf3e52c6c402f91738990db8cc48d52ebd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "print(f\"\ud83d\udcac Your query: {initial_prompt[:100]}{'...' if len(initial_prompt) > 100 else ''}\")\n        print(\"-\" * 60)\n        \n        # Prepare Claude Code command for interactive mode\n        cmd = ['claude-code']\n        if claude_args:\n            cmd.extend(claude_args)\n        \n        # Start Claude Code process\n        try:\n            process = subprocess.Popen(\n                cmd, \n                stdin=subprocess.PIPE, \n                stdout=subprocess.PIPE, \n                stderr=subprocess.PIPE,\n                text=True,\n                bufsize=1\n            )\n            \n            # Send initial prompt\n            process.stdin.write(initial_prompt + \"\\n\")\n            process.stdin.flush()\n            \n            # Interactive loop\n            while process.poll() is None:\n                try:\n                    # Read Claude's response\n                    output = process.stdout.readline()\n                    if output:\n                        print(output.rstrip())\n                    \n                    # Check for user input\n                    if sys.stdin in select.select([sys.stdin], [], [], 0)[0]:\n                        user_input = input()\n                        process.stdin.write(user_input + \"\\n\")\n                        process.stdin.flush()\n                        \n                except KeyboardInterrupt:\n                    process.terminate()\n                    break\n                    \n        except Exception as e:\n            logger.error(f\"Error running interactive Claude: {e}\")\n            print(f\"\u274c Error: {e}\")\n    \n    def search_and_show(self, query: str, top_k: int = 5, file_types: Optional[List[str]] = None) -> None:\n        \"\"\"Search and display results without running Claude\"\"\"\n        if not self.search_engine.load_index():\n            print(\"\u274c Could not load search index\")\n            return\n        \n        print(f\"\ud83d\udd0d Searching for: '{query}'\")\n        \n        if file_types:\n            results = self.search_engine.search_by_file_type(query, file_types, top_k)\n        else:\n            results = self.search_engine.search(query, top_k)\n        \n        if results:\n            formatted = self.search_engine.format_for_claude(results, query)\n            print(\"\\n\" + \"=\"*60)\n            print(\"\ud83d\udccb Search Results:\")\n            print(\"=\"*60)\n            print(formatted)\n            print(\"=\"*60)\n        else:\n            print(f\"\u274c No results found for: '{query}'\")\n    \n    def get_file_context(self, file_path: str) -> Optional[str]:\n        \"\"\"Get context for a specific file\"\"\"\n        if not self.search_engine.load_index():\n            return None\n        \n        summary = self.search_engine.get_file_summary(file_path)\n        if not summary:\n            return None\n        \n        return f\"\"\"# File Context: {file_path}\n\n**File Type:** {summary['file_type']}\n**Total Chunks:** {summary['total_chunks']}\n\n## Content Preview:\n```{summary['file_type'].lstrip('.')}\n{summary['content_preview']}\n```\n\"\"\"\n    \n    def find_similar_files(self, file_path: str, top_k: int = 5) -> List[str]:\n        \"\"\"Find files similar to the given file\"\"\"\n        if not self.search_engine.load_index():\n            return []\n        \n        return self.search_engine.get_similar_files(file_path, top_k)\n    \n    def show_stats(self) -> None:\n        \"\"\"Display index statistics\"\"\"\n        if not self.search_engine.load_index():\n            print(\"\u274c Could not load search index\")\n            return\n        \n        stats = self.search_engine.get_index_stats()\n        \n        print(\"\ud83d\udcca Index Statistics:\")\n        print(f\"  Project: {stats.get('project_path', 'Unknown')}\")\n        print(f\"  Documents: {stats.get('num_documents', 0)}\")\n        print(f\"  Chunks: {stats.get('num_chunks', 0)}\")\n        print(f\"  Embedding Model: {stats.get('embedding_model', 'Unknown')}\")\n        print(f\"  Created: {stats.get('created_at', 'Unknown')}\")\n        print(f\"  Extensions: {', '.join(stats.get('supported_extensions', []))}\")\n\ndef main():\n    \"\"\"CLI entry point\"\"\"\n    parser = argparse.ArgumentParser(\n        description='Run Claude Code with semantic context',\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nExamples:\n  # Basic usage with context\n  python claude.py \"How does authentication work?\"", "mimetype": "text/plain", "start_char_idx": 3634, "end_char_idx": 7948, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7ae2711c-832b-4e6d-be84-f96148f09e12": {"__data__": {"id_": "7ae2711c-832b-4e6d-be84-f96148f09e12", "embedding": null, "metadata": {"file_path": "src/integration/claude.py", "file_type": ".py", "file_name": "claude.py", "file_size": 11248}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "aedb53a0-4f44-4a05-a159-05dba419a589", "node_type": "4", "metadata": {"file_path": "src/integration/claude.py", "file_type": ".py", "file_name": "claude.py", "file_size": 11248}, "hash": "608e237cb49bea74f284d6cbf78955819cd01d85f3f29112f4b8a259f736499b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "958785fc-32e6-413b-934b-0d8194ed1c57", "node_type": "1", "metadata": {"file_path": "src/integration/claude.py", "file_type": ".py", "file_name": "claude.py", "file_size": 11248}, "hash": "9be3a20c0c1bdc428ccecb29526a70de07bbd788992541e3559f869a8c717140", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "# Search specific file types\n  python claude.py \"database queries\" --file-types py sql\n  \n  # Use different context query\n  python claude.py \"Add error handling\" --context-query \"error handling patterns\"\n  \n  # Just search without running Claude\n  python claude.py \"login function\" --search-only\n  \n  # Show file context\n  python claude.py --file-context src/auth.py\n  \n  # Find similar files\n  python claude.py --similar-files src/models/user.py\n        \"\"\"\n    )\n    \n    parser.add_argument('query', nargs='?', help='Your question/request for Claude')\n    parser.add_argument('--context-query', help='Specific query for context search')\n    parser.add_argument('--index-path', default='./claude_index', help='Path to index directory')\n    parser.add_argument('--top-k', type=int, default=3, help='Number of context chunks')\n    parser.add_argument('--file-types', nargs='+', help='Filter by file extensions (e.g., py js)')\n    parser.add_argument('--claude-args', nargs='*', help='Additional Claude Code arguments')\n    parser.add_argument('--search-only', action='store_true', help='Search without running Claude')\n    parser.add_argument('--interactive', action='store_true', help='Run Claude in interactive mode')\n    parser.add_argument('--file-context', help='Show context for specific file')\n    parser.add_argument('--similar-files', help='Find files similar to given file')\n    parser.add_argument('--stats', action='store_true', help='Show index statistics')\n    parser.add_argument('--verbose', '-v', action='store_true', help='Verbose logging')\n    \n    args = parser.parse_args()\n    \n    # Setup logging\n    if args.verbose:\n        logging.basicConfig(level=logging.INFO)\n    \n    # Create integration instance\n    integration = ClaudeCodeIntegration(args.index_path)\n    \n    # Handle different modes\n    if args.stats:\n        integration.show_stats()\n    elif args.file_context:\n        context = integration.get_file_context(args.file_context)\n        if context:\n            print(context)\n        else:\n            print(f\"\u274c No context found for file: {args.file_context}\")\n    elif args.similar_files:\n        similar = integration.find_similar_files(args.similar_files)\n        if similar:\n            print(f\"\ud83d\udcc1 Files similar to {args.similar_files}:\")\n            for i, f in enumerate(similar, 1):\n                print(f\"  {i}. {f}\")\n        else:\n            print(f\"\u274c No similar files found for: {args.similar_files}\")\n    elif args.query:\n        if args.search_only:\n            integration.search_and_show(\n                args.query, \n                args.top_k, \n                args.file_types\n            )\n        else:\n            # Prepare file types with dots\n            file_types = None\n            if args.file_types:\n                file_types = [f\".{ext}\" if not ext.startswith('.') else ext \n                            for ext in args.file_types]\n            \n            integration.run_with_context(\n                user_query=args.query,\n                context_query=args.context_query,\n                top_k=args.top_k,\n                file_types=file_types,\n                claude_args=args.claude_args,\n                interactive=args.interactive\n            )\n    else:\n        parser.print_help()\n\nif __name__ == \"__main__\":\n    main()", "mimetype": "text/plain", "start_char_idx": 7954, "end_char_idx": 11248, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ebeec2dd-c886-463e-b9c2-ec4469cf38c9": {"__data__": {"id_": "ebeec2dd-c886-463e-b9c2-ec4469cf38c9", "embedding": null, "metadata": {"file_path": "src/integration/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 132}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c549e2f8-8b7d-44e1-a33e-2b209fdd944d", "node_type": "4", "metadata": {"file_path": "src/integration/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 132}, "hash": "d0773c1eee05a8d30e6fe9c3aedc441c6b2955e14c786837d35b1e60a71c9fed", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"Integration module for Claude Code enhancement\"\"\"\n\nfrom .claude import ClaudeCodeIntegration\n\n__all__ = [\"ClaudeCodeIntegration\"]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 132, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e31ebede-0333-44d5-bde3-e05a19b4ae07": {"__data__": {"id_": "e31ebede-0333-44d5-bde3-e05a19b4ae07", "embedding": null, "metadata": {"file_path": "src/cli/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 44}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5f088bf9-80d3-4f10-8033-ad3b83aae3a2", "node_type": "4", "metadata": {"file_path": "src/cli/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 44}, "hash": "126c1114236f3289a083d54e42eae572e1c5dad7d3a22c7fe20938cd5ba5121e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"CLI module for command-line interfaces\"\"\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 44, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "54ba9dd5-ad05-48a4-9caa-4eb1e682f3e8": {"__data__": {"id_": "54ba9dd5-ad05-48a4-9caa-4eb1e682f3e8", "embedding": null, "metadata": {"file_path": "src/cli/search.py", "file_type": ".py", "file_name": "search.py", "file_size": 2688}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "cdb60186-b0f3-46cf-b596-630fecbf4ddf", "node_type": "4", "metadata": {"file_path": "src/cli/search.py", "file_type": ".py", "file_name": "search.py", "file_size": 2688}, "hash": "63ce3b3ed01b67f4dfb6d1d236d21a045961cd3f1955eb335edc0e500e0f4e2d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "#!/usr/bin/env python3\n\"\"\"\nStandalone search CLI for quick queries\n\"\"\"\n\nimport argparse\nimport sys\nfrom pathlib import Path\n\nfrom src.search.engine import SemanticSearchEngine\n\ndef main():\n    \"\"\"Quick search CLI entry point\"\"\"\n    parser = argparse.ArgumentParser(\n        description='Quick semantic search of indexed codebase'\n    )\n    \n    parser.add_argument('query', nargs='?', help='Search query')\n    parser.add_argument('--index-path', default='./claude_index',\n                       help='Path to index directory')\n    parser.add_argument('--top-k', type=int, default=5,\n                       help='Number of results')\n    parser.add_argument('--file-types', nargs='+',\n                       help='Filter by file extensions (py, js, etc.)')\n    parser.add_argument('--interactive', '-i', action='store_true',\n                       help='Interactive mode')\n    parser.add_argument('--score-threshold', type=float, default=0.0,\n                       help='Minimum relevance score')\n    parser.add_argument('--format', choices=['claude', 'simple'], default='claude',\n                       help='Output format')\n    \n    args = parser.parse_args()\n    \n    # Check if index exists\n    if not Path(args.index_path).exists():\n        print(f\"\u274c Index not found at {args.index_path}\")\n        print(\"Run 'python -m src.cli.main index <project_path>' first\")\n        sys.exit(1)\n    \n    engine = SemanticSearchEngine(args.index_path)\n    \n    if args.interactive or not args.query:\n        engine.interactive_search()\n    else:\n        if not engine.load_index():\n            print(\"\u274c Could not load search index\")\n            sys.exit(1)\n        \n        # Perform search\n        if args.file_types:\n            file_types = [f\".{ext}\" if not ext.startswith('.') else ext \n                         for ext in args.file_types]\n            results = engine.search_by_file_type(\n                args.query, file_types, args.top_k\n            )\n        else:\n            results = engine.search(\n                args.query, args.top_k, args.score_threshold\n            )\n        \n        # Display results\n        if not results:\n            print(f\"\u274c No results found for: '{args.query}'\")\n            sys.exit(1)\n        \n        if args.format == 'claude':\n            output = engine.format_for_claude(results, args.query)\n            print(output)\n        else:\n            print(f\"Results for: '{args.query}'\\n\")\n            for i, result in enumerate(results, 1):\n                print(f\"{i}. {result['file_path']} (score: {result.get('score', 0):.3f})\")\n                print(f\"   {result['content'][:100]}...\")\n                print()\n\nif __name__ == \"__main__\":\n    main()", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2688, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9f06c207-fbad-4213-a38f-86adf748a048": {"__data__": {"id_": "9f06c207-fbad-4213-a38f-86adf748a048", "embedding": null, "metadata": {"file_path": "src/cli/main.py", "file_type": ".py", "file_name": "main.py", "file_size": 7547}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ee727f5e-5f98-457e-9589-554599b9491c", "node_type": "4", "metadata": {"file_path": "src/cli/main.py", "file_type": ".py", "file_name": "main.py", "file_size": 7547}, "hash": "0750939bf60c444f7fe32f60029fc4f75cb3172049ffc06553bd2345d602e356", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f56e646a-58f5-4bbb-9b2c-2caebd679eab", "node_type": "1", "metadata": {}, "hash": "4efe8f6281d8728ff8d18dde9eed0849a6ccd5d803f831d54316b20a91cbb4e1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "#!/usr/bin/env python3\n\"\"\"\nMain CLI interface for Claude Codebase Indexer\n\"\"\"\n\nimport argparse\nimport sys\nimport logging\nfrom pathlib import Path\n\nfrom src.indexer.core import CodebaseIndexer\nfrom src.search.engine import SemanticSearchEngine\nfrom src.integration.claude import ClaudeCodeIntegration\n\ndef setup_logging(verbose: bool = False):\n    \"\"\"Setup logging configuration\"\"\"\n    level = logging.INFO if verbose else logging.WARNING\n    logging.basicConfig(\n        level=level,\n        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n\ndef cmd_index(args):\n    \"\"\"Index a codebase\"\"\"\n    setup_logging(args.verbose)\n    \n    indexer = CodebaseIndexer(args.project_path, args.index_path)\n    \n    if args.force or not Path(args.index_path).exists():\n        print(f\"\ud83d\ude80 Indexing codebase: {args.project_path}\")\n        if hasattr(args, 'dummy') and args.dummy:\n            print(\"\ud83e\uddea Using dummy embedder for testing\")\n            indexer.create_index(use_dummy=True)\n        else:\n            indexer.create_index()\n        print(\"\u2705 Indexing complete!\")\n    else:\n        print(f\"\u2139\ufe0f  Index already exists at {args.index_path}\")\n        print(\"   Use --force to recreate or run 'update' command\")\n\ndef cmd_search(args):\n    \"\"\"Search the indexed codebase\"\"\"\n    setup_logging(args.verbose)\n    \n    if args.interactive:\n        engine = SemanticSearchEngine(args.index_path)\n        engine.interactive_search()\n    else:\n        integration = ClaudeCodeIntegration(args.index_path)\n        \n        if args.file_types:\n            file_types = [f\".{ext}\" if not ext.startswith('.') else ext \n                         for ext in args.file_types]\n        else:\n            file_types = None\n            \n        integration.search_and_show(args.query, args.top_k, file_types)\n\ndef cmd_claude(args):\n    \"\"\"Run Claude Code with semantic context\"\"\"\n    setup_logging(args.verbose)\n    \n    integration = ClaudeCodeIntegration(args.index_path)\n    \n    # Prepare file types\n    file_types = None\n    if args.file_types:\n        file_types = [f\".{ext}\" if not ext.startswith('.') else ext \n                     for ext in args.file_types]\n    \n    integration.run_with_context(\n        user_query=args.query,\n        context_query=args.context_query,\n        top_k=args.top_k,\n        file_types=file_types,\n        claude_args=args.claude_args,\n        interactive=args.interactive\n    )\n\ndef cmd_stats(args):\n    \"\"\"Show index statistics\"\"\"\n    setup_logging(args.verbose)\n    \n    integration = ClaudeCodeIntegration(args.index_path)\n    integration.show_stats()\n\ndef cmd_similar(args):\n    \"\"\"Find similar files\"\"\"\n    setup_logging(args.verbose)\n    \n    integration = ClaudeCodeIntegration(args.index_path)\n    similar = integration.find_similar_files(args.file_path, args.top_k)\n    \n    if similar:\n        print(f\"\ud83d\udcc1 Files similar to {args.file_path}:\")\n        for i, f in enumerate(similar, 1):\n            print(f\"  {i}. {f}\")\n    else:\n        print(f\"\u274c No similar files found for: {args.file_path}\")\n\ndef cmd_update(args):\n    \"\"\"Update existing index\"\"\"\n    setup_logging(args.verbose)\n    \n    indexer = CodebaseIndexer(args.project_path, args.index_path)\n    \n    print(f\"\ud83d\udd04 Updating index for: {args.project_path}\")\n    indexer.update_index(force=args.force)\n    print(\"\u2705 Update complete!\")", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3320, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f56e646a-58f5-4bbb-9b2c-2caebd679eab": {"__data__": {"id_": "f56e646a-58f5-4bbb-9b2c-2caebd679eab", "embedding": null, "metadata": {"file_path": "src/cli/main.py", "file_type": ".py", "file_name": "main.py", "file_size": 7547}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ee727f5e-5f98-457e-9589-554599b9491c", "node_type": "4", "metadata": {"file_path": "src/cli/main.py", "file_type": ".py", "file_name": "main.py", "file_size": 7547}, "hash": "0750939bf60c444f7fe32f60029fc4f75cb3172049ffc06553bd2345d602e356", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9f06c207-fbad-4213-a38f-86adf748a048", "node_type": "1", "metadata": {"file_path": "src/cli/main.py", "file_type": ".py", "file_name": "main.py", "file_size": 7547}, "hash": "829a793f89162d5fc9a2c22246e09abff4028d9bbaf5e5a7f7d0519119ec1794", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "{f}\")\n    else:\n        print(f\"\u274c No similar files found for: {args.file_path}\")\n\ndef cmd_update(args):\n    \"\"\"Update existing index\"\"\"\n    setup_logging(args.verbose)\n    \n    indexer = CodebaseIndexer(args.project_path, args.index_path)\n    \n    print(f\"\ud83d\udd04 Updating index for: {args.project_path}\")\n    indexer.update_index(force=args.force)\n    print(\"\u2705 Update complete!\")\n\ndef main():\n    \"\"\"Main CLI entry point\"\"\"\n    parser = argparse.ArgumentParser(\n        description='Claude Codebase Indexer - Semantic search for Claude Code',\n        formatter_class=argparse.RawDescriptionHelpFormatter\n    )\n    \n    parser.add_argument('--index-path', default='./claude_index',\n                       help='Path to index directory (default: ./claude_index)')\n    \n    subparsers = parser.add_subparsers(dest='command', help='Available commands')\n    \n    # Index command\n    parser_index = subparsers.add_parser('index', help='Index a codebase')\n    parser_index.add_argument('project_path', help='Path to project directory')\n    parser_index.add_argument('--force', action='store_true', \n                             help='Force recreate existing index')\n    parser_index.add_argument('--verbose', '-v', action='store_true', \n                             help='Enable verbose logging')\n    parser_index.add_argument('--dummy', action='store_true', \n                             help='Use dummy embedder for testing (no OpenAI API required)')\n    parser_index.set_defaults(func=cmd_index)\n    \n    # Search command\n    parser_search = subparsers.add_parser('search', help='Search indexed codebase')\n    parser_search.add_argument('query', nargs='?', help='Search query')\n    parser_search.add_argument('--top-k', type=int, default=5, \n                              help='Number of results (default: 5)')\n    parser_search.add_argument('--file-types', nargs='+', \n                              help='Filter by file extensions')\n    parser_search.add_argument('--interactive', '-i', action='store_true',\n                              help='Interactive search mode')\n    parser_search.add_argument('--verbose', '-v', action='store_true', \n                              help='Enable verbose logging')\n    parser_search.set_defaults(func=cmd_search)\n    \n    # Claude command  \n    parser_claude = subparsers.add_parser('claude', help='Run Claude Code with context')\n    parser_claude.add_argument('query', help='Your question for Claude')\n    parser_claude.add_argument('--context-query', help='Specific context search query')\n    parser_claude.add_argument('--top-k', type=int, default=3,\n                              help='Number of context chunks (default: 3)')\n    parser_claude.add_argument('--file-types', nargs='+',\n                              help='Filter context by file extensions')\n    parser_claude.add_argument('--claude-args', nargs='*',\n                              help='Additional Claude Code arguments')\n    parser_claude.add_argument('--interactive', action='store_true',\n                              help='Run Claude in interactive mode')\n    parser_claude.add_argument('--verbose', '-v', action='store_true', \n                              help='Enable verbose logging')\n    parser_claude.set_defaults(func=cmd_claude)\n    \n    # Stats command\n    parser_stats = subparsers.add_parser('stats', help='Show index statistics')\n    parser_stats.set_defaults(func=cmd_stats)\n    \n    # Similar command\n    parser_similar = subparsers.add_parser('similar', help='Find similar files')\n    parser_similar.add_argument('file_path', help='File to find similarities for')\n    parser_similar.add_argument('--top-k', type=int, default=5,\n                               help='Number of similar files (default: 5)')\n    parser_similar.set_defaults(func=cmd_similar)\n    \n    # Update command\n    parser_update = subparsers.add_parser('update', help='Update existing index')\n    parser_update.add_argument('project_path', help='Path to project directory')\n    parser_update.add_argument('--force', action='store_true',\n                              help='Force full reindex')\n    parser_update.set_defaults(func=cmd_update)\n    \n    # Parse arguments\n    args = parser.parse_args()\n    \n    if not hasattr(args, 'func'):\n        parser.print_help()\n        sys.exit(1)\n    \n    try:\n        args.func(args)\n    except KeyboardInterrupt:\n        print(\"\\n\ud83d\udc4b Goodbye!\")\n        sys.exit(0)\n    except Exception as e:\n        if hasattr(args, 'verbose') and args.verbose:\n            raise\n        else:\n            print(f\"\u274c Error: {e}\")\n            sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()", "mimetype": "text/plain", "start_char_idx": 2946, "end_char_idx": 7547, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1eac9a52-74c1-422c-9cc8-1d27a6491b15": {"__data__": {"id_": "1eac9a52-74c1-422c-9cc8-1d27a6491b15", "embedding": null, "metadata": {"file_path": "src/search/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 125}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d85215e1-f865-48a0-b868-2455a609c183", "node_type": "4", "metadata": {"file_path": "src/search/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 125}, "hash": "85c633b8f2ff09bcda0c0b75bcbd4cebb634a2a309899eb9addb745ffc426fa2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"Search module for semantic code retrieval\"\"\"\n\nfrom .engine import SemanticSearchEngine\n\n__all__ = [\"SemanticSearchEngine\"]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 125, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "37e62612-f96d-4886-9a1c-33522855e3ba": {"__data__": {"id_": "37e62612-f96d-4886-9a1c-33522855e3ba", "embedding": null, "metadata": {"file_path": "src/search/engine.py", "file_type": ".py", "file_name": "engine.py", "file_size": 10357}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b9ddedf7-3bdd-444d-b747-b8bd92ea7a04", "node_type": "4", "metadata": {"file_path": "src/search/engine.py", "file_type": ".py", "file_name": "engine.py", "file_size": 10357}, "hash": "21bb465a3767549d128e92f7cb688e1ffc353c037a60b65e8c95346eb0c82594", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c8fb6bb7-2170-45d9-a650-83464749cc45", "node_type": "1", "metadata": {}, "hash": "8e0e270bfd5791bc5dcb8b65db738fd2d4c157acd0e28fe2b9a8a6afcdf63539", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "#!/usr/bin/env python3\n\"\"\"\nSemantic search engine for Claude Code integration\n\"\"\"\n\nimport json\nimport logging\nfrom pathlib import Path\nfrom typing import List, Dict, Optional, Any\n\nfrom llama_index.core import load_index_from_storage\nfrom llama_index.core.storage.storage_context import StorageContext\nfrom llama_index.core.schema import NodeWithScore\n\nlogger = logging.getLogger(__name__)\n\nclass SemanticSearchEngine:\n    \"\"\"Semantic search engine for code repositories\"\"\"\n    \n    def __init__(self, index_path: str = \"./claude_index\"):\n        self.index_path = Path(index_path)\n        self.index = None\n        self.metadata = None\n        \n    def load_index(self) -> bool:\n        \"\"\"Load the persisted index and metadata\"\"\"\n        if not self.index_path.exists():\n            logger.error(f\"Index not found at {self.index_path}\")\n            return False\n            \n        try:\n            # Load metadata\n            metadata_path = self.index_path / 'metadata.json'\n            if metadata_path.exists():\n                with open(metadata_path, 'r') as f:\n                    self.metadata = json.load(f)\n            \n            # Set up embedding model based on metadata\n            embed_model = None\n            if self.metadata and self.metadata.get('use_dummy', False):\n                from src.indexer.dummy_embedder import DummyEmbedding\n                embed_model = DummyEmbedding()\n            \n            # Load index\n            storage_context = StorageContext.from_defaults(\n                persist_dir=str(self.index_path)\n            )\n            \n            if embed_model:\n                self.index = load_index_from_storage(storage_context, embed_model=embed_model)\n            else:\n                self.index = load_index_from_storage(storage_context)\n            \n            logger.info(f\"Loaded index from {self.index_path}\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Failed to load index: {e}\")\n            return False\n    \n    def search(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n        \"\"\"Search for relevant code chunks\"\"\"\n        if not self.index:\n            if not self.load_index():\n                raise RuntimeError(\"Could not load search index\")\n        \n        # Get retriever\n        retriever = self.index.as_retriever(\n            similarity_top_k=top_k,\n            score_threshold=score_threshold\n        )\n        \n        # Retrieve relevant nodes\n        nodes = retriever.retrieve(query)\n        \n        # Format results\n        results = []\n        for i, node in enumerate(nodes):\n            metadata = node.metadata or {}\n            \n            result = {\n                'rank': i + 1,\n                'score': getattr(node, 'score', 0.0),\n                'content': node.text,\n                'file_path': metadata.get('file_path', 'unknown'),\n                'file_type': metadata.get('file_type', ''),\n                'file_name': metadata.get('file_name', ''),\n                'file_size': metadata.get('file_size', 0)\n            }\n            results.append(result)\n        \n        return results\n    \n    def search_by_file_type(self, query: str, file_extensions: List[str], \n                           top_k: int = 5) -> List[Dict[str, Any]]:\n        \"\"\"Search within specific file types\"\"\"\n        all_results = self.search(query, top_k * 2)  # Get more to filter\n        \n        # Filter by file extensions\n        filtered_results = [\n            result for result in all_results\n            if result['file_type'].lower() in [ext.lower() for ext in file_extensions]\n        ]\n        \n        return filtered_results[:top_k]\n    \n    def format_for_claude(self, results: List[Dict[str, Any]], query: str) -> str:\n        \"\"\"Format search results for Claude Code consumption\"\"\"\n        if not results:\n            return f\"# No results found for: '{query}'\"\n        \n        output_lines = [\n            f\"# Semantic Search Results for: '{query}'\",\n            f\"Found {len(results)} relevant code sections:\\n\"\n        ]\n        \n        for result in results:\n            file_path = result['file_path']\n            file_type = result['file_type'].lstrip('.')\n            score = result.get('score', 0.0)\n            \n            output_lines.extend([\n                f\"## Result {result['rank']}: {file_path}\",\n                f\"*Relevance Score: {score:.3f}*\\n\",\n                f\"```{file_type}\",\n                result['content'],\n                \"```\\n\"\n            ])\n        \n        return \"\\n\".join(output_lines)\n    \n    def get_file_summary(self, file_path: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Get summary information about a specific file\"\"\"\n        if not self.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4774, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c8fb6bb7-2170-45d9-a650-83464749cc45": {"__data__": {"id_": "c8fb6bb7-2170-45d9-a650-83464749cc45", "embedding": null, "metadata": {"file_path": "src/search/engine.py", "file_type": ".py", "file_name": "engine.py", "file_size": 10357}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b9ddedf7-3bdd-444d-b747-b8bd92ea7a04", "node_type": "4", "metadata": {"file_path": "src/search/engine.py", "file_type": ".py", "file_name": "engine.py", "file_size": 10357}, "hash": "21bb465a3767549d128e92f7cb688e1ffc353c037a60b65e8c95346eb0c82594", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "37e62612-f96d-4886-9a1c-33522855e3ba", "node_type": "1", "metadata": {"file_path": "src/search/engine.py", "file_type": ".py", "file_name": "engine.py", "file_size": 10357}, "hash": "6a65f5d518b4488eb21dd86b2152afbe34a33ad6139a5f4d6489f8b0c6e4fae8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8ec39862-e8a1-4237-96e1-405f5bc365a5", "node_type": "1", "metadata": {}, "hash": "ec5eee5e42e4e3f2bcae84d2d944d44ee16b8fe10c68bab02b907b36abc231d6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "f\"*Relevance Score: {score:.3f}*\\n\",\n                f\"```{file_type}\",\n                result['content'],\n                \"```\\n\"\n            ])\n        \n        return \"\\n\".join(output_lines)\n    \n    def get_file_summary(self, file_path: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Get summary information about a specific file\"\"\"\n        if not self.index:\n            if not self.load_index():\n                return None\n        \n        # Search for content from specific file\n        results = self.search(f\"file:{file_path}\", top_k=20)\n        \n        if not results:\n            return None\n        \n        # Aggregate information about the file\n        total_chunks = len([r for r in results if r['file_path'] == file_path])\n        file_content = \"\\n\".join([r['content'] for r in results if r['file_path'] == file_path])\n        \n        return {\n            'file_path': file_path,\n            'total_chunks': total_chunks,\n            'content_preview': file_content[:1000] + \"...\" if len(file_content) > 1000 else file_content,\n            'file_type': results[0]['file_type'] if results else 'unknown'\n        }\n    \n    def get_similar_files(self, file_path: str, top_k: int = 5) -> List[str]:\n        \"\"\"Find files similar to the given file\"\"\"\n        # Get content from the target file\n        file_summary = self.get_file_summary(file_path)\n        \n        if not file_summary:\n            return []\n        \n        # Search using the file's content\n        preview = file_summary['content_preview']\n        results = self.search(preview, top_k * 2)\n        \n        # Extract unique file paths, excluding the original\n        similar_files = []\n        seen_files = {file_path}\n        \n        for result in results:\n            result_file = result['file_path']\n            if result_file not in seen_files:\n                similar_files.append(result_file)\n                seen_files.add(result_file)\n                \n            if len(similar_files) >= top_k:\n                break\n        \n        return similar_files\n    \n    def get_index_stats(self) -> Dict[str, Any]:\n        \"\"\"Get statistics about the loaded index\"\"\"\n        if not self.metadata:\n            return {}\n        \n        return {\n            'project_path': self.metadata.get('project_path'),\n            'num_documents': self.metadata.get('num_documents', 0),\n            'num_chunks': self.metadata.get('num_chunks', 0),\n            'supported_extensions': self.metadata.get('supported_extensions', []),\n            'created_at': self.metadata.get('created_at'),\n            'embedding_model': self.metadata.get('embedding_model')\n        }\n    \n    def interactive_search(self):\n        \"\"\"Interactive search mode for testing\"\"\"\n        if not self.index:\n            if not self.load_index():\n                print(\"\u274c Could not load search index\")\n                return\n        \n        stats = self.get_index_stats()\n        print(f\"\ud83d\udd0d Claude Code Semantic Search\")\n        print(f\"\ud83d\udcc1 Project: {stats.get('project_path', 'Unknown')}\")\n        print(f\"\ud83d\udcca {stats.get('num_documents', 0)} files, {stats.get('num_chunks', 0)} chunks indexed\")\n        print(\"Type 'quit' to exit, 'help' for commands\\n\")\n        \n        while True:\n            try:\n                query = input(\"\ud83e\udd16 Search query > \").strip()\n                \n                if query.lower() in ['quit', 'exit', 'q']:\n                    break\n                elif query.lower() == 'help':\n                    print(\"\\nCommands:\")\n                    print(\"  <query>                - Semantic search\")\n                    print(\"  file:<path>           - Search specific file\")\n                    print(\"  type:<ext> <query>    - Search by file type (e.g., 'type:py authentication')\")\n                    print(\"  similar:<path>        - Find similar files\")\n                    print(\"  stats                 - Show index statistics\")\n                    print(\"  quit                  - Exit\\n\")\n                    continue\n                elif query.lower() == 'stats':\n                    stats = self.get_index_stats()\n                    for key, value in stats.items():\n                        print(f\"  {key}: {value}\")\n                    print()\n                    continue\n                elif not query:\n                    continue\n                \n                # Handle special commands\n                if query.startswith('type:'):\n                    parts = query.split(' ', 1)\n                    if len(parts) == 2:\n                        file_ext = parts[0].", "mimetype": "text/plain", "start_char_idx": 4419, "end_char_idx": 8975, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8ec39862-e8a1-4237-96e1-405f5bc365a5": {"__data__": {"id_": "8ec39862-e8a1-4237-96e1-405f5bc365a5", "embedding": null, "metadata": {"file_path": "src/search/engine.py", "file_type": ".py", "file_name": "engine.py", "file_size": 10357}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b9ddedf7-3bdd-444d-b747-b8bd92ea7a04", "node_type": "4", "metadata": {"file_path": "src/search/engine.py", "file_type": ".py", "file_name": "engine.py", "file_size": 10357}, "hash": "21bb465a3767549d128e92f7cb688e1ffc353c037a60b65e8c95346eb0c82594", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c8fb6bb7-2170-45d9-a650-83464749cc45", "node_type": "1", "metadata": {"file_path": "src/search/engine.py", "file_type": ".py", "file_name": "engine.py", "file_size": 10357}, "hash": "dfe4eb2a8c35f72593bd904ff25fe79da2cf1acaca78f49f91de001a14234009", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "lower() == 'stats':\n                    stats = self.get_index_stats()\n                    for key, value in stats.items():\n                        print(f\"  {key}: {value}\")\n                    print()\n                    continue\n                elif not query:\n                    continue\n                \n                # Handle special commands\n                if query.startswith('type:'):\n                    parts = query.split(' ', 1)\n                    if len(parts) == 2:\n                        file_ext = parts[0].split(':', 1)[1]\n                        search_query = parts[1]\n                        results = self.search_by_file_type(search_query, [f\".{file_ext}\"])\n                    else:\n                        print(\"Usage: type:<extension> <query>\")\n                        continue\n                elif query.startswith('similar:'):\n                    file_path = query.split(':', 1)[1]\n                    similar = self.get_similar_files(file_path)\n                    print(f\"\\nSimilar files to {file_path}:\")\n                    for i, f in enumerate(similar, 1):\n                        print(f\"  {i}. {f}\")\n                    print()\n                    continue\n                else:\n                    results = self.search(query)\n                \n                # Display results\n                if results:\n                    formatted = self.format_for_claude(results, query)\n                    print(\"\\n\" + \"=\"*60)\n                    print(\"\ud83d\udcce Copy this to Claude Code:\")\n                    print(\"=\"*60)\n                    print(formatted)\n                    print(\"=\"*60 + \"\\n\")\n                else:\n                    print(f\"\u274c No results found for: '{query}'\\n\")\n                    \n            except KeyboardInterrupt:\n                print(\"\\n\ud83d\udc4b Goodbye!\")\n                break\n            except Exception as e:\n                print(f\"\u274c Error: {e}\\n\")", "mimetype": "text/plain", "start_char_idx": 8445, "end_char_idx": 10357, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7321996d-6ade-4de9-a50b-69c1adf43d77": {"__data__": {"id_": "7321996d-6ade-4de9-a50b-69c1adf43d77", "embedding": null, "metadata": {"file_path": "src/indexer/dummy_embedder.py", "file_type": ".py", "file_name": "dummy_embedder.py", "file_size": 933}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3a5c2614-53a2-415f-9de0-385f40a911c7", "node_type": "4", "metadata": {"file_path": "src/indexer/dummy_embedder.py", "file_type": ".py", "file_name": "dummy_embedder.py", "file_size": 933}, "hash": "323b9a744213c9dccd2d75b25b9c1bcfacaf6636b25e79fe00ae5e3c69baad08", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "#!/usr/bin/env python3\n\"\"\"\nDummy embedder for testing without OpenAI API\n\"\"\"\n\nimport numpy as np\nfrom llama_index.core.embeddings import BaseEmbedding\n\nclass DummyEmbedding(BaseEmbedding):\n    \"\"\"Simple dummy embedder for testing without requiring external APIs\"\"\"\n    \n    def _get_text_embedding(self, text: str) -> list[float]:\n        # Create a simple hash-based embedding with fixed dimension\n        hash_val = hash(text)\n        np.random.seed(abs(hash_val) % (2**32))\n        embedding = np.random.normal(0, 1, 384)  # Fixed dimension\n        return embedding.tolist()\n    \n    def _get_query_embedding(self, query: str) -> list[float]:\n        return self._get_text_embedding(query)\n    \n    async def _aget_query_embedding(self, query: str) -> list[float]:\n        return self._get_text_embedding(query)\n    \n    async def _aget_text_embedding(self, text: str) -> list[float]:\n        return self._get_text_embedding(text)", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 933, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "39876ac9-f351-433c-a3c8-4b3426850700": {"__data__": {"id_": "39876ac9-f351-433c-a3c8-4b3426850700", "embedding": null, "metadata": {"file_path": "src/indexer/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 116}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "03658bb1-a01d-44ae-9ac4-72e4dd081cf8", "node_type": "4", "metadata": {"file_path": "src/indexer/__init__.py", "file_type": ".py", "file_name": "__init__.py", "file_size": 116}, "hash": "b4b24c11a02b07bae8e6930085b37e79823d48660233a2535502ab489fc88434", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\"\"\"Indexing module for codebase semantic search\"\"\"\n\nfrom .core import CodebaseIndexer\n\n__all__ = [\"CodebaseIndexer\"]", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 116, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dd09a0f4-8d36-4e4d-982c-fa7a7f322cf6": {"__data__": {"id_": "dd09a0f4-8d36-4e4d-982c-fa7a7f322cf6", "embedding": null, "metadata": {"file_path": "src/indexer/core.py", "file_type": ".py", "file_name": "core.py", "file_size": 7362}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0a1ac987-95cf-430b-90e8-3c0a787adac9", "node_type": "4", "metadata": {"file_path": "src/indexer/core.py", "file_type": ".py", "file_name": "core.py", "file_size": 7362}, "hash": "23b1d5b7bab9e9040f562557d24de0923e219296fcfc1ab65cc90caf3756dd45", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8ca1b90d-c8fa-46fd-8756-b357d02a9b2a", "node_type": "1", "metadata": {}, "hash": "2a5e99370666b58b81abe359c153da6883f52592a9ad6699f7f6fa9402e6888d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "#!/usr/bin/env python3\n\"\"\"\nSemantic codebase indexer for Claude Code integration\n\"\"\"\n\nimport os\nimport json\nimport logging\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional\n\nfrom llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Document, load_index_from_storage\nfrom llama_index.core.node_parser import CodeSplitter\nfrom llama_index.vector_stores.faiss import FaissVectorStore\nfrom llama_index.core.storage.storage_context import StorageContext\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nimport faiss\nimport pandas as pd\n\nlogger = logging.getLogger(__name__)\n\nclass CodebaseIndexer:\n    \"\"\"Semantic indexer for code repositories\"\"\"\n    \n    def __init__(self, project_path: str, index_path: str = \"./claude_index\"):\n        self.project_path = Path(project_path)\n        self.index_path = Path(index_path)\n        self.supported_extensions = {\n            '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.cpp', '.c', \n            '.h', '.hpp', '.cs', '.php', '.rb', '.go', '.rs', '.swift',\n            '.kt', '.scala', '.sh', '.sql', '.yaml', '.yml', '.json',\n            '.md', '.txt', '.rst', '.toml', '.cfg', '.ini'\n        }\n        \n        # Directories to skip during indexing\n        self.skip_dirs = {\n            'node_modules', '.git', '__pycache__', '.pytest_cache',\n            'venv', 'env', '.venv', 'dist', 'build', '.next',\n            'target', 'bin', 'obj', '.mypy_cache', 'coverage',\n            '.tox', '.nox', 'htmlcov'\n        }\n        \n    def should_index_file(self, file_path: Path) -> bool:\n        \"\"\"Determine if a file should be indexed\"\"\"\n        if file_path.suffix.lower() not in self.supported_extensions:\n            return False\n            \n        # Check if any parent directory should be skipped\n        if any(part in self.skip_dirs for part in file_path.parts):\n            return False\n            \n        # Skip very large files (>1MB)\n        try:\n            if file_path.stat().st_size > 1024 * 1024:\n                logger.warning(f\"Skipping large file: {file_path}\")\n                return False\n        except OSError:\n            return False\n            \n        return True\n    \n    def load_documents(self) -> List[Document]:\n        \"\"\"Load and filter documents from the project\"\"\"\n        documents = []\n        \n        logger.info(f\"Scanning project directory: {self.project_path}\")\n        \n        for file_path in self.project_path.rglob('*'):\n            if file_path.is_file() and self.should_index_file(file_path):\n                try:\n                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                        content = f.read()\n                        \n                    # Skip empty files\n                    if not content.strip():\n                        continue\n                        \n                    # Create relative path for metadata\n                    rel_path = file_path.relative_to(self.project_path)\n                    \n                    doc = Document(\n                        text=content,\n                        metadata={\n                            'file_path': str(rel_path),\n                            'file_type': file_path.suffix,\n                            'file_name': file_path.name,\n                            'file_size': len(content)\n                        }\n                    )\n                    documents.append(doc)\n                    \n                except Exception as e:\n                    logger.warning(f\"Could not read {file_path}: {e}\")\n                    \n        logger.info(f\"Loaded {len(documents)} documents\")\n        return documents\n    \n    def create_index(self, embedding_model: str = \"text-embedding-ada-002\", use_dummy: bool = False) -> VectorStoreIndex:\n        \"\"\"Create and persist the vector index\"\"\"\n        logger.info(f\"Creating index for {self.project_path}\")\n        \n        documents = self.load_documents()\n        if not documents:\n            raise ValueError(\"No documents found to index\")\n        \n        # Use simple text splitter for reliability\n        from llama_index.core.node_parser import SimpleNodeParser\n        splitter = SimpleNodeParser.from_defaults(\n            chunk_size=1000,\n            chunk_overlap=100\n        )\n        \n        nodes = splitter.get_nodes_from_documents(documents)\n        logger.info(f\"Created {len(nodes)} semantic chunks\")\n        \n        # Set up embedding model\n        if use_dummy:\n            from .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4493, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8ca1b90d-c8fa-46fd-8756-b357d02a9b2a": {"__data__": {"id_": "8ca1b90d-c8fa-46fd-8756-b357d02a9b2a", "embedding": null, "metadata": {"file_path": "src/indexer/core.py", "file_type": ".py", "file_name": "core.py", "file_size": 7362}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0a1ac987-95cf-430b-90e8-3c0a787adac9", "node_type": "4", "metadata": {"file_path": "src/indexer/core.py", "file_type": ".py", "file_name": "core.py", "file_size": 7362}, "hash": "23b1d5b7bab9e9040f562557d24de0923e219296fcfc1ab65cc90caf3756dd45", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dd09a0f4-8d36-4e4d-982c-fa7a7f322cf6", "node_type": "1", "metadata": {"file_path": "src/indexer/core.py", "file_type": ".py", "file_name": "core.py", "file_size": 7362}, "hash": "799b2111149508c1ea1ac968511598058b1305b086a4508d4c5c924f0ea78b59", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "core.node_parser import SimpleNodeParser\n        splitter = SimpleNodeParser.from_defaults(\n            chunk_size=1000,\n            chunk_overlap=100\n        )\n        \n        nodes = splitter.get_nodes_from_documents(documents)\n        logger.info(f\"Created {len(nodes)} semantic chunks\")\n        \n        # Set up embedding model\n        if use_dummy:\n            from .dummy_embedder import DummyEmbedding\n            embed_model = DummyEmbedding()\n            dimension = 384  # Dummy embedding dimension\n        else:\n            embed_model = OpenAIEmbedding(model=embedding_model)\n            dimension = 1536  # OpenAI embedding dimension\n        \n        # Create vector store (use simple storage for testing)\n        if use_dummy:\n            # Use in-memory storage for dummy embedder\n            storage_context = StorageContext.from_defaults()\n        else:\n            # Use FAISS for production\n            faiss_index = faiss.IndexFlatL2(dimension)\n            vector_store = FaissVectorStore(faiss_index=faiss_index)\n            storage_context = StorageContext.from_defaults(vector_store=vector_store)\n        \n        # Build index\n        logger.info(\"Building vector index...\")\n        index = VectorStoreIndex(\n            nodes, \n            storage_context=storage_context,\n            embed_model=embed_model\n        )\n        \n        # Create index directory\n        self.index_path.mkdir(parents=True, exist_ok=True)\n        \n        # Persist index\n        index.storage_context.persist(persist_dir=str(self.index_path))\n        \n        # Save metadata\n        metadata = {\n            'project_path': str(self.project_path),\n            'index_path': str(self.index_path),\n            'num_documents': len(documents),\n            'num_chunks': len(nodes),\n            'supported_extensions': list(self.supported_extensions),\n            'embedding_model': embedding_model if not use_dummy else 'dummy',\n            'embedding_dimension': dimension,\n            'use_dummy': use_dummy,\n            'created_at': str(pd.Timestamp.now())\n        }\n        \n        with open(self.index_path / 'metadata.json', 'w') as f:\n            json.dump(metadata, f, indent=2)\n        \n        logger.info(f\"Index created successfully at {self.index_path}\")\n        return index\n    \n    def update_index(self, force: bool = False) -> VectorStoreIndex:\n        \"\"\"Update existing index or create new one\"\"\"\n        if self.index_path.exists() and not force:\n            logger.info(\"Index already exists. Use force=True to recreate.\")\n            return self.load_existing_index()\n        \n        return self.create_index()\n    \n    def load_existing_index(self) -> Optional[VectorStoreIndex]:\n        \"\"\"Load an existing index from disk\"\"\"\n        if not self.index_path.exists():\n            return None\n            \n        try:\n            storage_context = StorageContext.from_defaults(\n                persist_dir=str(self.index_path)\n            )\n            index = load_index_from_storage(storage_context)\n            logger.info(f\"Loaded existing index from {self.index_path}\")\n            return index\n        except Exception as e:\n            logger.error(f\"Failed to load index: {e}\")\n            return None", "mimetype": "text/plain", "start_char_idx": 4119, "end_char_idx": 7362, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"8fdcd5d8-0e93-4859-a98e-e358e9a16060": {"doc_hash": "89a4133cde43740b27d50612cd7d4fc7e2a7ab678bf6a2c0e68086785ba14e83", "ref_doc_id": "697366ad-6178-4dc0-9563-c62376bf54e0"}, "071400f5-a926-45f2-98e3-561158dc325b": {"doc_hash": "ad2a86af781ba2ba66f34b4f037876919a63a16684cf16c114f74d129ec3cc49", "ref_doc_id": "bbb98c35-7b97-4ae5-9ca1-58dbc4b1a8d2"}, "bbbd87d7-508f-4041-87cb-9590d2c3f786": {"doc_hash": "06c4d5aa705702e17630859d56c32eb77fc57d36b459fe5dd219b73bdf5bbd27", "ref_doc_id": "21fd938d-2298-4743-8c2d-a1754f4a83d1"}, "263432b9-dd92-4eb5-9147-1a13ad8eb92a": {"doc_hash": "b93ed98103861136c2bc20f7e94c168492a5d2a4b7cd49055de8f93b7dbac964", "ref_doc_id": "37934402-8bf4-4850-944e-21fc4ecadd57"}, "f45ed685-0050-4e5d-b7bf-20dc3b8307ee": {"doc_hash": "8c59623f119642d94d4ea366dc7f34072510000c598848a98a2d63897b9aa4cb", "ref_doc_id": "f0b9f952-4eef-486d-851d-9ede5e8b2043"}, "5263c7d9-8d40-449f-a423-46df09298c43": {"doc_hash": "f306534d371596629c31cf9bfce029e5f59677fbb60cc92d6bfe954070f068a4", "ref_doc_id": "f0b9f952-4eef-486d-851d-9ede5e8b2043"}, "42cb9e8c-cf4b-4667-bc8e-0ffa83fd78fe": {"doc_hash": "065bab27d0a3367684d94cd76e7dff9a384b9ffe767e6c6e3027293cc35c4f87", "ref_doc_id": "f0b9f952-4eef-486d-851d-9ede5e8b2043"}, "d517282d-44c9-4ca4-8cb5-a1fbfd1374da": {"doc_hash": "f8849e60cd9500096a62beffdbe6cfb845976c2401acc9c61a201b19a37a540d", "ref_doc_id": "0302bcac-3671-411b-9718-2e6aa790625f"}, "e66cbdd2-ca39-41aa-8723-65d9e26f3e1e": {"doc_hash": "f8732272ce7d494d435e691cddbe5e451b3aeb0ba066677cbf8b9f50a041ea79", "ref_doc_id": "dd1f44ac-60e2-45d9-8825-4e0bb1f099e6"}, "8bdc9650-5544-421d-9787-b330984b5eae": {"doc_hash": "684e729dc313e0402428c5ead29be898c4c9679e3b1bb1438f6dc748b53499bd", "ref_doc_id": "f3e3c43a-ca2f-41ce-9595-2a318444f954"}, "4a5a38ea-1804-469e-8ef4-40cc4d13c433": {"doc_hash": "3c41ff5b07ba010da3c34cc7cbae37bb32d52b9bb00394d880441f2ab96d992e", "ref_doc_id": "aedb53a0-4f44-4a05-a159-05dba419a589"}, "958785fc-32e6-413b-934b-0d8194ed1c57": {"doc_hash": "9be3a20c0c1bdc428ccecb29526a70de07bbd788992541e3559f869a8c717140", "ref_doc_id": "aedb53a0-4f44-4a05-a159-05dba419a589"}, "7ae2711c-832b-4e6d-be84-f96148f09e12": {"doc_hash": "0c8158776b42eb3da551f843892a42a210c4493069f889ca5b5e8b2469cf13ad", "ref_doc_id": "aedb53a0-4f44-4a05-a159-05dba419a589"}, "ebeec2dd-c886-463e-b9c2-ec4469cf38c9": {"doc_hash": "ff72d8a37966e61d6adb42134a1d449a6d7bfda72b249a943fd2b1928d99d439", "ref_doc_id": "c549e2f8-8b7d-44e1-a33e-2b209fdd944d"}, "e31ebede-0333-44d5-bde3-e05a19b4ae07": {"doc_hash": "1a1fb9fe85cc83759cec2c805a3b868dfdf4d944c970a58f53b95948bc2860fe", "ref_doc_id": "5f088bf9-80d3-4f10-8033-ad3b83aae3a2"}, "54ba9dd5-ad05-48a4-9caa-4eb1e682f3e8": {"doc_hash": "e4e094c1298e0fe2c07563d072ab3f637887fda14d6732087a0c1427dede9774", "ref_doc_id": "cdb60186-b0f3-46cf-b596-630fecbf4ddf"}, "9f06c207-fbad-4213-a38f-86adf748a048": {"doc_hash": "829a793f89162d5fc9a2c22246e09abff4028d9bbaf5e5a7f7d0519119ec1794", "ref_doc_id": "ee727f5e-5f98-457e-9589-554599b9491c"}, "f56e646a-58f5-4bbb-9b2c-2caebd679eab": {"doc_hash": "774b19c8fee3145c73b52595badbbb578d76c8adf6b4a4ad9536be0c139ee039", "ref_doc_id": "ee727f5e-5f98-457e-9589-554599b9491c"}, "1eac9a52-74c1-422c-9cc8-1d27a6491b15": {"doc_hash": "111242ca837f8aa4c31b73fbf7857123ebd97f8c2a4002877289978f9d9d26de", "ref_doc_id": "d85215e1-f865-48a0-b868-2455a609c183"}, "37e62612-f96d-4886-9a1c-33522855e3ba": {"doc_hash": "6a65f5d518b4488eb21dd86b2152afbe34a33ad6139a5f4d6489f8b0c6e4fae8", "ref_doc_id": "b9ddedf7-3bdd-444d-b747-b8bd92ea7a04"}, "c8fb6bb7-2170-45d9-a650-83464749cc45": {"doc_hash": "dfe4eb2a8c35f72593bd904ff25fe79da2cf1acaca78f49f91de001a14234009", "ref_doc_id": "b9ddedf7-3bdd-444d-b747-b8bd92ea7a04"}, "8ec39862-e8a1-4237-96e1-405f5bc365a5": {"doc_hash": "7b9bf38973c5498e10a2bb2112fe15230e07c57b5f1ccc018427b89bfcf50ed4", "ref_doc_id": "b9ddedf7-3bdd-444d-b747-b8bd92ea7a04"}, "7321996d-6ade-4de9-a50b-69c1adf43d77": {"doc_hash": "55ecda162e64439971205e50bf158bfe05e26626c97bacbad4485f87f5368754", "ref_doc_id": "3a5c2614-53a2-415f-9de0-385f40a911c7"}, "39876ac9-f351-433c-a3c8-4b3426850700": {"doc_hash": "28b3a6fa2630b35102bd94d8a869aaa892d5ec9f0b47acbe140b338578c3c247", "ref_doc_id": "03658bb1-a01d-44ae-9ac4-72e4dd081cf8"}, "dd09a0f4-8d36-4e4d-982c-fa7a7f322cf6": {"doc_hash": "799b2111149508c1ea1ac968511598058b1305b086a4508d4c5c924f0ea78b59", "ref_doc_id": "0a1ac987-95cf-430b-90e8-3c0a787adac9"}, "8ca1b90d-c8fa-46fd-8756-b357d02a9b2a": {"doc_hash": "97405255490ec071bd20350f9052bafcb867872fa90f99596c07f2dcc66c59f6", "ref_doc_id": "0a1ac987-95cf-430b-90e8-3c0a787adac9"}}}